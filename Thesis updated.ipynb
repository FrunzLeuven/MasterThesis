{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 445,
   "id": "694b7456",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutup; shutup.please()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "id": "51d46f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 5000)\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from mlxtend.frequent_patterns import fpgrowth, apriori\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from spmf import Spmf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "id": "01469f2d-fe5c-46cf-ba6c-7cf265e3379b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_preprocessing(df):\n",
    "    df = df.dropna()\n",
    "    df['charttime'] = pd.to_datetime(df['charttime'])\n",
    "    df['hadm_id'] = df['hadm_id'].astype(int)\n",
    "    # combine admission with subject_ids\n",
    "    df['subject_id'] = df['subject_id'].astype(\"str\")+\"_\"+df['hadm_id'].astype(\"str\")\n",
    "    df = df.drop_duplicates()\n",
    "    return df\n",
    "    \n",
    "def map_mimic_to_loinc(df):\n",
    "    lonic = pd.read_csv(\"./mimic_to_loinc.csv\") \n",
    "    joined_df = pd.merge(df.query(\"tbl_name=='labevents'\"), lonic, how='inner', left_on='col_id', right_on='itemid')\n",
    "    lab_events = joined_df[['subject_id', 'hadm_id', 'charttime', 'loinc_code', 'tbl_name']].dropna().drop_duplicates()\n",
    "    lab_events = lab_events.rename(columns={\"loinc_code\":\"col_id\"})\n",
    "    df = pd.concat([df.query(\"tbl_name!='labevents'\"), lab_events]).reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "# Generate unique 5-length digit IDs for each string\n",
    "def generate_string_pharm(df):\n",
    "    unique_strings = df.query(\"tbl_name=='pharmacy'\")['col_id'].drop_duplicates().tolist()\n",
    "    id_mapping = {string: f\"{index:05}\" for index, string in enumerate(unique_strings)}\n",
    "    pharm_mapping = pd.DataFrame(list(id_mapping.items()), columns=['col_id', 'new_col_id'])\n",
    "    return pharm_mapping\n",
    "\n",
    "def map_pharmacy_codes(df, pharm_mapping):\n",
    "    df = pd.merge(df, pharm_mapping, how='left', left_on='col_id', right_on='col_id')\n",
    "    df['col_id'] = (np.where(df['tbl_name'] == 'pharmacy', df['new_col_id'], df['col_id']))\n",
    "    df = df.drop(columns=[\"new_col_id\"])\n",
    "    return df\n",
    "\n",
    "def add_prefix(df):\n",
    "    # create a prefix based on 3 characters of each tbl_name\n",
    "    df['prefix'] = df['tbl_name'].apply(lambda x: x[0:3]+'_')\n",
    "    # add the prefix to the col_id\n",
    "    df['col_id'] = df['prefix']+df['col_id']\n",
    "    df = df.drop(columns=[\"hadm_id\", \"prefix\"])\n",
    "    return df\n",
    "\n",
    "def group_into_list(df):\n",
    "    df = df.sort_values(['subject_id','charttime'], ascending=[True, True])\n",
    "    # add all items to a list \n",
    "    df = (df.groupby(['subject_id', 'charttime'])['col_id'].apply(list)\n",
    "            .reset_index(name='col_id_list'))\n",
    "    return df\n",
    "\n",
    "def closed_patterns(frequent):\n",
    "    su = frequent.support.unique()#all unique support count\n",
    "    #Dictionay storing itemset with same support count key\n",
    "    fredic = {}\n",
    "    for i in range(len(su)):\n",
    "        inset = list(frequent.loc[frequent.support ==su[i]]['itemsets'])\n",
    "        fredic[su[i]] = inset\n",
    "    #Dictionay storing itemset with  support count <= key\n",
    "    fredic2 = {}\n",
    "    for i in range(len(su)):\n",
    "        inset2 = list(frequent.loc[frequent.support<=su[i]]['itemsets'])\n",
    "        fredic2[su[i]] = inset2\n",
    "    \n",
    "    #Find Closed frequent itemset\n",
    "    cl = []\n",
    "    for index, row in frequent.iterrows():\n",
    "        isclose = True\n",
    "        cli = row['itemsets']\n",
    "        cls = row['support']\n",
    "        checkset = fredic[cls]\n",
    "        for i in checkset:\n",
    "            if (cli!=i):\n",
    "                if(frozenset.issubset(cli,i)):\n",
    "                    isclose = False\n",
    "                    break\n",
    "        \n",
    "        if(isclose):\n",
    "            cl.append(row['itemsets'])\n",
    "    return cl\n",
    "    \n",
    "def generate_frequent_itemsets(df, min_support):\n",
    "    te = TransactionEncoder()\n",
    "    te_ary = te.fit(df[ \"col_id_list\"].to_list()).transform(df[ \"col_id_list\"].to_list())\n",
    "    onehot = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "    patterns = fpgrowth(onehot, min_support=min_support, use_colnames=True)\n",
    "    patterns['itemsets'] = patterns['itemsets'].apply(lambda x: frozenset(x))\n",
    "    cl = closed_patterns(patterns)\n",
    "    patterns = patterns[patterns['itemsets'].isin(cl)]\n",
    "    return patterns\n",
    "\n",
    "def get_buckets(patterns):\n",
    "    patterns['length'] = patterns['itemsets'].apply(len)\n",
    "    patterns = patterns.sort_values([\"length\", \"support\"],ascending=[False, False])\n",
    "    \n",
    "    buckets = (patterns\n",
    "               .groupby(['length'])['itemsets'].apply(list).reset_index(name='buckets')\n",
    "              ).sort_values(\"length\",ascending=False)['buckets'].to_list()       \n",
    "    \n",
    "    return buckets\n",
    "\n",
    "def basket_mappings(patterns):\n",
    "    long_baskets = patterns.query(\"length>1\")['itemsets'].drop_duplicates().to_list()\n",
    "    id_mapping_basket = {string: frozenset({f\"basket_{index:05}\"}) for index, string in enumerate(long_baskets)}\n",
    "    mapping_basket_df = pd.DataFrame(list(id_mapping_basket.items()), columns=['basket', 'basket_id'])\n",
    "    return id_mapping_basket, mapping_basket_df\n",
    "    \n",
    "def break_down(pattern, buckets, id_mapping_basket):\n",
    "    best_subsets = []\n",
    "    for B in buckets:\n",
    "        if len(B[0])<len(pattern):\n",
    "            for SE in B:\n",
    "                if SE.issubset(pattern):\n",
    "                    best_subsets.append(SE)\n",
    "                    pattern = pattern.difference(SE)\n",
    "                    if not pattern:\n",
    "                         return best_subsets\n",
    "    best_subsets = [id_mapping_basket[best_subset] for best_subset in best_subsets if len(best_subset)>1]\n",
    "    if pattern:\n",
    "        best_subsets.append(pattern)\n",
    "    \n",
    "    return frozenset.union(*best_subsets)   \n",
    "    \n",
    "def get_final_mapping(df):\n",
    "    df = df.sort_values(['subject_id','charttime'], ascending=[True, True])\n",
    "    df['col_id_list'] = df['col_id_list'].apply(list)\n",
    "    all_items_mapping = df.explode('col_id_list')['col_id_list'].drop_duplicates().reset_index(drop=True).to_dict()\n",
    "    reverse_final_mapping = df.explode('col_id_list')['col_id_list'].drop_duplicates().reset_index(drop=True).to_dict()\n",
    "    final_mapping = {v: k for k, v in reverse_final_mapping.items()}\n",
    "    return final_mapping, reverse_final_mapping\n",
    "\n",
    "def apply_mapping(item_list, final_mapping):\n",
    "    return [final_mapping[item] for item in item_list]\n",
    "\n",
    "def get_sequences(df):\n",
    "    sequences = df.groupby(['subject_id'])['col_id_list'].apply(list).reset_index(name='sequences')['sequences'].to_list()\n",
    "    return sequences\n",
    "\n",
    "def convert_string_list(string_list):\n",
    "    return [list(map(int, s.split())) if ' ' in s else [int(s)] for s in string_list]\n",
    "\n",
    "def reverse_apply_final_mapping(pattern):\n",
    "    mapped_pattern = []\n",
    "    for sublist in pattern:\n",
    "        mapped_sublist = [reverse_final_mapping[num] for num in sublist]\n",
    "        mapped_pattern.append(mapped_sublist)\n",
    "    return mapped_pattern\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "id": "9d529f29-b883-4ba5-ba1e-77d33ffb8869",
   "metadata": {},
   "outputs": [],
   "source": [
    "lonic = pd.read_csv(\"./mimic_to_loinc.csv\") \n",
    "path = \"./mimic_raw_data2.csv\"\n",
    "df = pd.read_csv(path) \n",
    "df = basic_preprocessing(df)\n",
    "df = map_mimic_to_loinc(df)\n",
    "pharm_mapping = generate_string_pharm(df)\n",
    "df = map_pharmacy_codes(df, pharm_mapping)\n",
    "df = add_prefix(df)\n",
    "df = group_into_list(df)\n",
    "#patterns = generate_frequent_itemsets(df, 0.01)\n",
    "id_mapping_basket, mapping_basket_df = basket_mappings(patterns)\n",
    "df['col_id_list'] = df[\"col_id_list\"].apply(lambda x: break_down(frozenset(x), buckets, id_mapping_basket))\n",
    "final_mapping, reverse_final_mapping = get_final_mapping(df)\n",
    "df['col_id_list'] = df['col_id_list'].apply(lambda x: apply_mapping(x, final_mapping))\n",
    "sequences = get_sequences(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "id": "524e4667-c882-4ce2-a795-3ba336fcdb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "spmf = Spmf(\"CloSpan\", input_direct=sequences,\n",
    "             arguments=[0.05,\"\", True])\n",
    "spmf.run()\n",
    "# print(spmf.parse_output())\n",
    "df_spmf = spmf.to_pandas_dataframe(pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "id": "1c94532c-6827-47bc-99d9-9d208c4d1f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spmf['pattern'] = df_spmf['pattern'].apply(convert_string_list)\n",
    "df_spmf['pattern'] = df_spmf['pattern'].apply(reverse_apply_final_mapping)\n",
    "df_spmf['len'] = df_spmf['pattern'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "id": "978a5764-67f6-48d1-b67d-14e59f9cd858",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#df_spmf.query(\"len>1\").sort_values(\"sup\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "id": "72190be6-dcc7-4be9-81bc-823d0c65f853",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#mapping_basket_df[mapping_basket_df[\"basket_id\"] == frozenset({\"basket_01639\"})]['basket'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "id": "7c35beff-dc27-4ea6-a748-2d0bcf4c2dc6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#lonic[lonic['loinc_code']=='1959-6']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "id": "5994c214-ffa9-4a3f-8195-91479b7965ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#pharm_mapping.query(\"new_col_id == '00002'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
