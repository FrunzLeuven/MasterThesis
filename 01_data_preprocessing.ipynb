{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d791a852-be52-42de-8fb8-63786b4dd6fa",
   "metadata": {},
   "source": [
    "##### Last update - 15th April\n",
    "Erik Hambardzumyan "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15592e25-e1dc-4d33-8b7f-12e21f2a9322",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Outline\n",
    "### -  1. Data querying from Mimic IV\n",
    "### -  2. Data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "841bfac5-8652-4685-86ff-f022341c009c",
   "metadata": {},
   "source": [
    "# 0. Basic imports & functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a9ce894-168a-462f-8a6f-b9dd203b8751",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import pickle\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 500)\n",
    "import datetime\n",
    "import numpy as np\n",
    "from mlxtend.frequent_patterns import fpgrowth, apriori, fpmax\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from spmf import Spmf\n",
    "import shutup; shutup.please()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ff298ff5-84c7-4cb8-95a3-a6198d7747bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_query_postgres(query):\n",
    "    \"\"\"\n",
    "    Executes queries on postgresql database\n",
    "    \"\"\"\n",
    "    \n",
    "    # Establishing the connection\n",
    "    conn = psycopg2.connect(\n",
    "        dbname=\"mimiciv\",\n",
    "        user=\"\",\n",
    "        password=\"\",\n",
    "        host=\"localhost\",\n",
    "        port=5431\n",
    "    )\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    # Executing a SQL query\n",
    "    cursor.execute(query)\n",
    "    \n",
    "    record = cursor.fetchall()\n",
    "    \n",
    "    # Closing the cursor & connection\n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "    return record\n",
    "\n",
    "def lab_and_pharma_events():\n",
    "    query = \"\"\"\n",
    "    SELECT * FROM (\n",
    "        SELECT SUBJECT_ID,\n",
    "                HADM_ID,\n",
    "                CHARTTIME,\n",
    "                ITEMID::TEXT AS COL_ID,\n",
    "                'labevents' AS TBL_NAME\n",
    "                FROM MIMICIV_HOSP.LABEVENTS AS LABEVENTS_FULL\n",
    "                UNION ALL \n",
    "        SELECT SUBJECT_ID,\n",
    "                HADM_ID,\n",
    "                COALESCE(VERIFIEDTIME,STARTTIME) AS CHARTTIME,\n",
    "                MEDICATION AS COL_ID,\n",
    "                'pharmacy' AS TBL_NAME\n",
    "                FROM MIMICIV_HOSP.PHARMACY) as EVENTS\n",
    "                WHERE EVENTS.HADM_ID is not NULL\n",
    "            \"\"\"\n",
    "    records = execute_query_postgres(query)\n",
    "    chunk_size = 100000  # ### Process data in batches, you can adjust this according to your system's capacity\n",
    "    cols = ['subject_id', 'hadm_id', 'charttime', 'col_id', 'tbl_name']\n",
    "    \n",
    "    data_frames = []\n",
    "    for i in range(0, len(records), chunk_size):\n",
    "        chunk = records[i:i+chunk_size]\n",
    "        df_chunk = pd.DataFrame(chunk, columns=cols)\n",
    "        data_frames.append(df_chunk)\n",
    "    \n",
    "    # Union all chunks\n",
    "    final_df = pd.concat(data_frames)\n",
    "    final_df.to_csv(\"./full_db.csv\", index=False)\n",
    "    \n",
    "def diagnosis_events():\n",
    "    query = \"\"\"Select \n",
    "    diag.subject_id, \n",
    "    diag.hadm_id,\n",
    "    diag.seq_num,\n",
    "    diag.icd_code,\n",
    "    diag.icd_version,\n",
    "    d_icd_diagnoses.long_title \n",
    "    from mimiciv_hosp.diagnoses_icd AS diag \n",
    "                JOIN mimiciv_hosp.d_icd_diagnoses AS d_icd_diagnoses ON \n",
    "    \t\t\t\t\t\t\t\t\t\t\tdiag.icd_code = d_icd_diagnoses.icd_code\n",
    "    \t\t\t\t\t\t\t\t\t\t\tAND diag.icd_version = d_icd_diagnoses.icd_version\n",
    "    \"\"\"\n",
    "    \n",
    "    records = execute_query_postgres(query)\n",
    "    \n",
    "    chunk_size = 100000  Process data in batches, you can adjust this according to your system's capacity\n",
    "    cols = ['subject_id', 'hadm_id','seq_num', 'icd_code', 'icd_version', 'long_title']\n",
    "    \n",
    "    data_frames = []\n",
    "    for i in range(0, len(records), chunk_size):\n",
    "        chunk = records[i:i+chunk_size]\n",
    "        df_chunk = pd.DataFrame(chunk, columns=cols)\n",
    "        data_frames.append(df_chunk)\n",
    "    \n",
    "    # Union all chunks\n",
    "    final_df = pd.concat(data_frames)\n",
    "    final_df['icd_code'] = final_df['icd_code'].str.strip()\n",
    "    final_df['icd_code'] = final_df['icd_code'].astype(\"str\")+\"_\"+final_df['icd_version'].astype(\"str\")\n",
    "    final_df['subject_id'] = final_df['subject_id'].astype(\"str\")+\"_\"+final_df['hadm_id'].astype(\"str\")\n",
    "    final_df.drop(columns=\"hadm_id\", inplace=True)\n",
    "    final_df[\"icd_code\"] = \"diag_\"+final_df[\"icd_code\"]\n",
    "    final_df.to_csv(\"./diag3.csv\", index=False)\n",
    "\n",
    "def basic_preprocessing(df):\n",
    "    \"\"\"\n",
    "    Drops nulls, combines subject_id and admission id, drops duplicates\n",
    "    \"\"\"\n",
    "    df = df.dropna()\n",
    "    df['charttime'] = pd.to_datetime(df['charttime'])\n",
    "    df['hadm_id'] = df['hadm_id'].astype(int)\n",
    "    # combine admission with subject_ids\n",
    "    df['subject_id'] = df['subject_id'].astype(\"str\")+\"_\"+df['hadm_id'].astype(\"str\")\n",
    "    df = df.drop_duplicates().drop(columns=[\"hadm_id\"])\n",
    "    return df\n",
    "    \n",
    "def map_mimic_to_loinc(df):\n",
    "    \"\"\"\n",
    "    Maps lab events ids to loinc codes, the cases that aren't joined are filtered\n",
    "    e.g. a lot of lab events are CBC (complete blood count)\n",
    "    \"\"\"\n",
    "    lonic = pd.read_csv(\"./mimic_to_loinc.csv\") \n",
    "    lonic.itemid = lonic.itemid.astype(\"string\")\n",
    "    joined_df = pd.merge(df.query(\"tbl_name=='labevents'\"), lonic, how='inner', left_on='col_id', right_on='itemid')\n",
    "    lab_events = joined_df[['subject_id','charttime', 'loinc_code', 'tbl_name']].dropna().drop_duplicates()\n",
    "    lab_events = lab_events.rename(columns={\"loinc_code\":\"col_id\"})\n",
    "    df = pd.concat([df.query(\"tbl_name!='labevents'\"), lab_events]).reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "def convert_to_frozenset(loinc_list):\n",
    "    return frozenset(loinc_list.split(', '))\n",
    "\n",
    "def break_down(pattern, buckets, id_mapping_basket):\n",
    "    \"\"\"\n",
    "    Breaking Down Same Time Concurrent Events (STCE). Algorithm 1 from\n",
    "    Efficient Mining Template of Predictive Temporal Clinical Event Patterns From Patient Electronic Medical Records\n",
    "    by Jianqiang Li et al.\n",
    "\n",
    "    The idea is to find longest subset by length that maps to a group, then the processes is repeated for remaining items.\n",
    "    For instance, if a patient orders lab items \"ABCDE,\" and \"ABC\" belong to a panel or frequent basket, they are assigned basket code,\n",
    "    and the algorithm iterates on the remaining \"DE\".\n",
    "    \"\"\"\n",
    "    best_subsets = []\n",
    "    output = pattern \n",
    "    for B in buckets:\n",
    "        if len(B[0])<len(pattern):\n",
    "            for SE in B:\n",
    "                if SE.issubset(pattern):\n",
    "                    best_subsets.append(SE)\n",
    "                    pattern = pattern.difference(SE)\n",
    "                    if not pattern:\n",
    "                         break\n",
    "    if len(best_subsets)>0:\n",
    "        best_subsets = [id_mapping_basket[best_subset] if len(best_subset) > 1 else best_subset for best_subset in best_subsets]\n",
    "        if pattern:\n",
    "            best_subsets.append(pattern)\n",
    "        output = frozenset.union(*best_subsets)\n",
    "    return list(output)\n",
    "\n",
    "def convert_loinc_to_panel(df):\n",
    "    \"\"\"\n",
    "    Group loinc ids into panels\n",
    "    \"\"\"\n",
    "    loinc_panels = pd.read_csv(\"./mimic_loinc_panels.csv\")\n",
    "    # convet lists to frozen sets and add length of LoincList\n",
    "    loinc_panels['LoincList'] = loinc_panels['LoincList'].apply(convert_to_frozenset) \n",
    "    loinc_panels['ParentLoinc'] = loinc_panels['ParentLoinc'].apply(lambda x: frozenset([x]))\n",
    "    loinc_panels['length'] = loinc_panels['LoincList'].apply(len)\n",
    "    # group panels by length\n",
    "    loinc_dict = dict(zip(loinc_panels['LoincList'], loinc_panels['ParentLoinc']))\n",
    "    buckets_loinc = (loinc_panels.groupby(['length'])['LoincList']\n",
    "                                 .apply(list).reset_index(name='buckets')\n",
    "                                 .sort_values(\"length\",ascending=False)['buckets'].to_list()) \n",
    "    \n",
    "    lab_panels = group_into_list(df.query(\"tbl_name=='labevents'\"))\n",
    "    # this is where magic happens\n",
    "    lab_panels['col_id_list'] = lab_panels[\"col_id_list\"].apply(lambda x: break_down(frozenset(x), buckets_loinc, loinc_dict))\n",
    "    # after we have them in a list, we have to explode the table back to its original form\n",
    "    lab_panels = lab_panels.explode('col_id_list').rename(columns={'col_id_list': 'col_id'})\n",
    "    lab_panels['tbl_name'] = 'labevents'\n",
    "    # add other tables  \n",
    "    df = pd.concat([df.query(\"tbl_name!='labevents'\"), lab_panels]).reset_index(drop=True)\n",
    "    return df\n",
    "    \n",
    "def generate_string_pharm(df):\n",
    "    \"\"\"\n",
    "    Generate unique 5-length digit IDs for each pharmacy strings\n",
    "    \"\"\"\n",
    "    unique_strings = df.query(\"tbl_name=='pharmacy'\")['col_id'].drop_duplicates().tolist()\n",
    "    id_mapping = {string: f\"{index:05}\" for index, string in enumerate(unique_strings)}\n",
    "    pharm_mapping = pd.DataFrame(list(id_mapping.items()), columns=['col_id', 'new_col_id'])\n",
    "    return pharm_mapping\n",
    "\n",
    "def map_pharmacy_codes(df, pharm_mapping):\n",
    "    \"\"\"\n",
    "    Map pharm names to 5-length digits\n",
    "    \"\"\"\n",
    "    df = pd.merge(df, pharm_mapping, how='left', left_on='col_id', right_on='col_id')\n",
    "    df['col_id'] = (np.where(df['tbl_name'] == 'pharmacy', df['new_col_id'], df['col_id']))\n",
    "    df = df.drop(columns=[\"new_col_id\"])\n",
    "    return df\n",
    "\n",
    "def add_prefix(df):\n",
    "    \"\"\"\n",
    "    Add a prefix based on 3 characters of each tbl_name to col_id\n",
    "    \"\"\"\n",
    "    # create a prefix based on 3 characters of each tbl_name\n",
    "    df['prefix'] = df['tbl_name'].apply(lambda x: x[0:3]+'_')\n",
    "    # add the prefix to the col_id\n",
    "    df['col_id'] = df['prefix']+df['col_id']\n",
    "    df = df.drop(columns=[\"prefix\"])\n",
    "    return df\n",
    "\n",
    "def group_into_list(df):\n",
    "    \"\"\"\n",
    "    For each subject_id obtain list of all items that were charted together\n",
    "    \"\"\"\n",
    "    df = df.sort_values(['subject_id','charttime'], ascending=[True, True])\n",
    "    # add all items to a list \n",
    "    df = (df.groupby(['subject_id', 'charttime'])['col_id'].apply(list)\n",
    "            .reset_index(name='col_id_list'))\n",
    "    return df\n",
    "    \n",
    "def generate_frequent_itemsets(df, min_support):\n",
    "    \"\"\"\n",
    "    Generate frequent itemsets\n",
    "    \"\"\"\n",
    "    te = TransactionEncoder()\n",
    "    te_ary = te.fit(df[ \"col_id_list\"].to_list()).transform(df[ \"col_id_list\"].to_list())\n",
    "    onehot = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "    patterns = fpmax(onehot, min_support=min_support, use_colnames=True)\n",
    "    patterns['itemsets'] = patterns['itemsets'].apply(lambda x: frozenset(x))\n",
    "    return patterns\n",
    "\n",
    "def get_buckets(patterns):\n",
    "    \"\"\"\n",
    "    Buckets aim to group items by by descending length and within each bucket, items are sorted based on their support (highest first)\n",
    "    \"\"\"\n",
    "    patterns['length'] = patterns['itemsets'].apply(len)\n",
    "    patterns = patterns.sort_values([\"length\", \"support\"],ascending=[False, False])\n",
    "    buckets = (patterns\n",
    "               .groupby(['length'])['itemsets'].apply(list).reset_index(name='buckets')\n",
    "              ).sort_values(\"length\",ascending=False)['buckets'].to_list()       \n",
    "    \n",
    "    return buckets\n",
    "\n",
    "def basket_mappings(patterns):\n",
    "    \"\"\"\n",
    "    Create unique IDs for frequent baskets \n",
    "    \"\"\"\n",
    "    long_baskets = patterns.query(\"length>1\")['itemsets'].drop_duplicates().to_list()\n",
    "    id_mapping_basket = {string: frozenset({f\"basket_{index:05}\"}) for index, string in enumerate(long_baskets)}\n",
    "    mapping_basket_df = pd.DataFrame(list(id_mapping_basket.items()), columns=['basket', 'basket_id'])\n",
    "    return id_mapping_basket, mapping_basket_df\n",
    "\n",
    "def convert_string_list(string_list):\n",
    "    return [list(map(int, s.split())) if ' ' in s else [int(s)] for s in string_list]\n",
    "\n",
    "\n",
    "def to_pandas_dataframe(self, pickle=False):\n",
    "    \"\"\"\n",
    "    Convert output to pandas DataFrame\n",
    "    pickle: Save as serialized pickle\n",
    "    \"\"\"\n",
    "    # TODO: Optional parameter for pickle file name\n",
    "\n",
    "    if not self.patterns_:\n",
    "        self.parse_output()\n",
    "\n",
    "    patterns_dict_list = []\n",
    "    for pattern_sup in self.patterns_:\n",
    "        pattern = pattern_sup[:-1]\n",
    "        sup_info = pattern_sup[-1:][0]\n",
    "        sup = int(sup_info.split(\"#SUP:\")[1].split()[0])\n",
    "        sids = [int(sid) for sid in sup_info.split(\"#SID:\")[1].strip().split()]\n",
    "\n",
    "        patterns_dict_list.append({'pattern': pattern, 'sup': sup, 'sid_list': sids})\n",
    "    \n",
    "    df = pd.DataFrame(patterns_dict_list)\n",
    "    self.df_ = df\n",
    "\n",
    "    if pickle:\n",
    "        df.to_pickle(self.output_.replace(\".txt\", \".pkl\"))\n",
    "    return df\n",
    "\n",
    "def combine_datasets():\n",
    "    df = pd.read_csv(\"./ready_for_seq_mining.csv\", converters={'col_id_list': ast.literal_eval})\n",
    "    df['len'] = df['col_id_list'].apply(len)\n",
    "    df['eventID'] = (df\n",
    "        .sort_values(['subject_id','charttime'], ascending=[True, True])\n",
    "        .groupby(['subject_id']).cumcount() + 1)\n",
    "    # make sure subject and seq num is unique otherwise it's a bug\n",
    "    diag = pd.read_csv(\"diag3.csv\").drop_duplicates(subset=['subject_id', 'seq_num'])\n",
    "    \n",
    "    # Take maximum seq number for each subject\n",
    "    max_event = diag.groupby('subject_id')['seq_num'].max().reset_index(name='seq_num')\n",
    "    \n",
    "    # Join it with main events and make sure that eventID is after the maximum seq number of the diagnosis\n",
    "    df = pd.merge(df,max_event, on='subject_id')\n",
    "    df[\"eventID\"] = df[\"eventID\"]+df[\"seq_num\"]\n",
    "    \n",
    "    # rename\n",
    "    diag.rename(columns=dict(zip(diag.columns, [\"subject_id\",\"eventID\",\"col_id_list\"])), inplace=True)\n",
    "    diag['col_id_list'] = diag['col_id_list'].apply(lambda x:[x])\n",
    "    # only keep those diagnosis events that have lab events\n",
    "    diag = pd.merge(df[['subject_id']].drop_duplicates(), diag, on='subject_id')\n",
    "    \n",
    "    # Add diagnoses\n",
    "    unioned = pd.concat([df[['subject_id',\"eventID\", \"col_id_list\"]], \n",
    "                       diag[['subject_id',\"eventID\", \"col_id_list\"]]])\n",
    "    # add lengths of itemsets\n",
    "    unioned['length_items'] = unioned['col_id_list'].apply(len)\n",
    "    \n",
    "    # sort by \"subject_id\", \"eventID\"\n",
    "    unioned = (unioned[['subject_id', \"eventID\", \"length_items\",\"col_id_list\"]]\n",
    "              .sort_values([\"subject_id\", \"eventID\"])\n",
    "    ).reset_index(drop=True)\n",
    "\n",
    "    unioned.to_csv('arules_input_final_mimic_raw.txt', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2caf2334-2006-447c-9254-ce63d60a68a8",
   "metadata": {},
   "source": [
    "# 1. Data querying from Mimic IV\n",
    "[Mimic-IV](https://mimic.mit.edu/docs/iv/) contains real data of patients’ hospital admissions to a tertiary academic medical center in Boston, MA, USA (also see [github repository](https://github.com/MIT-LCP/mimic-code/tree/main/mimic-iv)). Our primary focus lies on the 'hosp' (hospital) module, housing comprehensive data such as laboratory orders and prescribed medications. It's important to note that not all data within this module originates directly from the hospital; some may stem from the emergency department, albeit stored within the hospital's Electronic Health Record (EHR) system.\n",
    "\n",
    "For our data mining purposes, we combine two tables: 'labevents' for laboratory measurements and 'pharmacy' for prescribed medications. The selected columns include:\n",
    "\n",
    "- SUBJECT_ID - identifier of the patient.\n",
    "- HADM_ID - identifier of the admission.\n",
    "- CHARTTIME - The time at which the laboratory measurement was charted.,\n",
    "for pharmacy it is the time that the prescription was verified or entered into the system.\n",
    "- COL_ID - An identifier which uniquely denotes laboratory items, or presciption name for pharmacy.\n",
    "- TBL_NAME - signififies the table source 'pharmacy' or 'labevents'\n",
    "\n",
    "We are interesed in data within one admission, therefore we filter out cases where *hadm_id* is absent. hile there are a total of 431K admissions, not all lab events are linked to an 'hadm_id'. The absence of this identifier suggests that the lab sample may have been collected outside the hospital premises. Outside the hospital encompasses areas such as the emergency department, which operates as a clinic until the patient is formally admitted (see the [discussion thread](https://github.com/MIT-LCP/mimic-code/issues/1703)). Consequently, only 351K admissions are associated with a lab event. \n",
    "\n",
    "\n",
    "To elaborate on the nature of lab events, specimens are collected from a patient, such as a urine sample to measure pH or a blood sample for a complete blood count. The 'Charttime' timestamp denotes when the specimen was collected. Consequently, multiple orders may share the same specimen charttime because a single sample can be used for different laboratory measurements."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9f0ad8-b0e6-46b4-af62-85e352532de3",
   "metadata": {},
   "source": [
    "#### 1.1 Diagnosis events extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e0a7810c-8092-47e9-a2dd-06db7f038660",
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnosis_events()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac056b13-771c-4444-b441-01eac012a851",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>seq_num</th>\n",
       "      <th>icd_code</th>\n",
       "      <th>icd_version</th>\n",
       "      <th>long_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000032_22595853</td>\n",
       "      <td>2</td>\n",
       "      <td>diag_78959_9</td>\n",
       "      <td>9</td>\n",
       "      <td>Other ascites</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000032_22595853</td>\n",
       "      <td>4</td>\n",
       "      <td>diag_07070_9</td>\n",
       "      <td>9</td>\n",
       "      <td>Unspecified viral hepatitis C without hepatic ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000032_22595853</td>\n",
       "      <td>6</td>\n",
       "      <td>diag_29680_9</td>\n",
       "      <td>9</td>\n",
       "      <td>Bipolar disorder, unspecified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000032_22595853</td>\n",
       "      <td>7</td>\n",
       "      <td>diag_30981_9</td>\n",
       "      <td>9</td>\n",
       "      <td>Posttraumatic stress disorder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000032_22841357</td>\n",
       "      <td>2</td>\n",
       "      <td>diag_78959_9</td>\n",
       "      <td>9</td>\n",
       "      <td>Other ascites</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          subject_id  seq_num      icd_code  icd_version  \\\n",
       "0  10000032_22595853        2  diag_78959_9            9   \n",
       "1  10000032_22595853        4  diag_07070_9            9   \n",
       "2  10000032_22595853        6  diag_29680_9            9   \n",
       "3  10000032_22595853        7  diag_30981_9            9   \n",
       "4  10000032_22841357        2  diag_78959_9            9   \n",
       "\n",
       "                                          long_title  \n",
       "0                                      Other ascites  \n",
       "1  Unspecified viral hepatitis C without hepatic ...  \n",
       "2                      Bipolar disorder, unspecified  \n",
       "3                      Posttraumatic stress disorder  \n",
       "4                                      Other ascites  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"./diag3.csv\").head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d81cf1-a514-49f5-b585-e45dc8058986",
   "metadata": {},
   "source": [
    "#### 1.2 Obtain pharmacy and lab events raw data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed75cc4c-e9fc-4a30-9f4f-c53140e38bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_and_pharma_events()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "561765b9-5921-4289-b8c9-383be5094efa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>charttime</th>\n",
       "      <th>col_id</th>\n",
       "      <th>tbl_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12968666</td>\n",
       "      <td>26897334</td>\n",
       "      <td>2116-12-29 10:15:00</td>\n",
       "      <td>50912</td>\n",
       "      <td>labevents</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12967791</td>\n",
       "      <td>27191750</td>\n",
       "      <td>2195-08-27 10:15:00</td>\n",
       "      <td>50856</td>\n",
       "      <td>labevents</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12967791</td>\n",
       "      <td>27191750</td>\n",
       "      <td>2195-08-27 10:15:00</td>\n",
       "      <td>50868</td>\n",
       "      <td>labevents</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12967791</td>\n",
       "      <td>27191750</td>\n",
       "      <td>2195-08-27 10:15:00</td>\n",
       "      <td>50879</td>\n",
       "      <td>labevents</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12967791</td>\n",
       "      <td>27191750</td>\n",
       "      <td>2195-08-27 10:15:00</td>\n",
       "      <td>50880</td>\n",
       "      <td>labevents</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id   hadm_id            charttime col_id   tbl_name\n",
       "0    12968666  26897334  2116-12-29 10:15:00  50912  labevents\n",
       "1    12967791  27191750  2195-08-27 10:15:00  50856  labevents\n",
       "2    12967791  27191750  2195-08-27 10:15:00  50868  labevents\n",
       "3    12967791  27191750  2195-08-27 10:15:00  50879  labevents\n",
       "4    12967791  27191750  2195-08-27 10:15:00  50880  labevents"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"./full_db.csv\").head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93966745-b15c-4b2e-afa9-71a9ed22c4e0",
   "metadata": {},
   "source": [
    "#### Obtain all Mimic IV admissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0efaa1a1-c428-47c0-84c0-f91caf369d45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(431231,)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"\"\"Select count(*) from MIMICIV_HOSP.admissions\"\"\"\n",
    "\n",
    "execute_query_postgres(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b705778-0e4d-4f20-a8d7-d2cf2e19f946",
   "metadata": {},
   "source": [
    "# 2. Data preprocessing\n",
    "Here is the outline of steps:\n",
    "-  2.1 Basic preprocessing\n",
    "-  2.2 Map item ids to loinc codes\n",
    "-  2.3 Group loinc codes to panels\n",
    "-  2.4 Map 5-digit codes to pharmacy\n",
    "-  2.5 Filter out subjects who had presriptions only and no labevents\n",
    "-  2.6 For each subject create an ordered list of item orders to prepare for data mining\n",
    "-  2.7 STCE breakdown with frequent baskets (a.k.a itemsets)\n",
    "- 2.8 Combine datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f1aac889-68ed-4198-b649-712d6bc21cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./full_db.csv\").query(\"tbl_name!='microbiologyevents'\").query(\"tbl_name!='procedures_icd'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c84b8d-38db-4d58-b6da-b5820a4e7fda",
   "metadata": {},
   "source": [
    "##### How many concurrent events per event type?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b7644c09-0713-4b64-9de5-0acecd381ccd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tbl_name</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>labevents</th>\n",
       "      <td>16.757969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pharmacy</th>\n",
       "      <td>1.941792</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                size\n",
       "tbl_name            \n",
       "labevents  16.757969\n",
       "pharmacy    1.941792"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby([\"subject_id\", \"hadm_id\", \"charttime\", \"tbl_name\"]).size() \\\n",
    "  .reset_index(name='size') \\\n",
    "  .groupby(\"tbl_name\") \\\n",
    "  .agg({\"size\": np.mean})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd683a4a-9ab3-414c-b8a0-2b9147beff54",
   "metadata": {},
   "source": [
    "#### 2.0 Raw table: labevents 60.6M labevents "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "923ea0c1-c463-4f9d-bead-d30fdf6d5137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tbl_name\n",
      "labevents    60601911\n",
      "pharmacy     12689767\n",
      "dtype: int64\n",
      "tbl_name\n",
      "labevents    351034\n",
      "pharmacy     365405\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "## transactions per table\n",
    "print(df.groupby(\"tbl_name\").size())\n",
    "# admissions per table\n",
    "print(df[['hadm_id', 'tbl_name']].drop_duplicates().groupby(\"tbl_name\").size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2525b2ef-0ebb-4cad-955d-fb41e36b80d3",
   "metadata": {},
   "source": [
    "#### 2.1 Basic preprocessing\n",
    "This step includes combining subject id with admission id (*hadm_d*), filtering \"Sodium Chloride 0.9%  Flush\" from pharmacy,\n",
    "      finally removing any null values or duplicate rows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e1d093-919f-40ee-b43f-c47e872e30ac",
   "metadata": {},
   "source": [
    "##### How many patients were presribed \"Sodium Chloride 0.9%  Flush\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "89a6b0cc-4289-4870-b2ca-737de5127d5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91.36015691983148"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df.query(\"col_id == 'Sodium Chloride 0.9%  Flush'\")['subject_id'].drop_duplicates().shape[0]/\n",
    "df['subject_id'].drop_duplicates().shape[0)]*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "10098dfa-4901-48d1-995a-fc1e9bdb6436",
   "metadata": {},
   "outputs": [],
   "source": [
    "# very repetitive pharmacy, needs to be removed\n",
    "df = df.query(\"col_id != 'Sodium Chloride 0.9%  Flush'\")\n",
    "df = basic_preprocessing(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fafe0801-df35-4167-9694-037d4e9c076b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>charttime</th>\n",
       "      <th>col_id</th>\n",
       "      <th>tbl_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12968666_26897334</td>\n",
       "      <td>2116-12-29 10:15:00</td>\n",
       "      <td>50912</td>\n",
       "      <td>labevents</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12967791_27191750</td>\n",
       "      <td>2195-08-27 10:15:00</td>\n",
       "      <td>50856</td>\n",
       "      <td>labevents</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12967791_27191750</td>\n",
       "      <td>2195-08-27 10:15:00</td>\n",
       "      <td>50868</td>\n",
       "      <td>labevents</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          subject_id           charttime col_id   tbl_name\n",
       "0  12968666_26897334 2116-12-29 10:15:00  50912  labevents\n",
       "1  12967791_27191750 2195-08-27 10:15:00  50856  labevents\n",
       "2  12967791_27191750 2195-08-27 10:15:00  50868  labevents"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4867a73f-447e-4f9d-9060-7805a84186b4",
   "metadata": {},
   "source": [
    "##### 60.6M to 60.5M after basic preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7c2d59af-2047-4dad-9449-1ab2e484ee2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tbl_name\n",
      "labevents    60495669\n",
      "pharmacy     10862892\n",
      "dtype: int64\n",
      "tbl_name\n",
      "labevents    351034\n",
      "pharmacy     365269\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.groupby(\"tbl_name\").size())\n",
    "print(df[['subject_id', 'tbl_name']].drop_duplicates().groupby(\"tbl_name\").size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2cb920f-b9fa-4844-bd8e-08b87e2b0f42",
   "metadata": {},
   "source": [
    "#### 2.2 Map item ids to loinc codes\n",
    "Logical Observation Identifiers Names and Codes (LOINC) is a database which aims to standardize medical laboratory test orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "877ceae9-c490-48e3-addf-240a676612e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.col_id = df.col_id.astype(\"string\")\n",
    "df = map_mimic_to_loinc(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d09843bd-26cb-4a56-a4ef-7b0e4261d42d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>charttime</th>\n",
       "      <th>col_id</th>\n",
       "      <th>tbl_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12968666_26897334</td>\n",
       "      <td>2116-12-29 10:15:00</td>\n",
       "      <td>2160-0</td>\n",
       "      <td>labevents</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12967791_27191750</td>\n",
       "      <td>2195-08-27 10:15:00</td>\n",
       "      <td>3298-7</td>\n",
       "      <td>labevents</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12967791_27191750</td>\n",
       "      <td>2195-08-27 10:15:00</td>\n",
       "      <td>3376-1</td>\n",
       "      <td>labevents</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          subject_id           charttime  col_id   tbl_name\n",
       "0  12968666_26897334 2116-12-29 10:15:00  2160-0  labevents\n",
       "1  12967791_27191750 2195-08-27 10:15:00  3298-7  labevents\n",
       "2  12967791_27191750 2195-08-27 10:15:00  3376-1  labevents"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.query(\"tbl_name=='labevents'\").head(3).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1934e26-4248-409c-ac80-cdb75ef0b7be",
   "metadata": {},
   "source": [
    "##### After joining with loinc codes 60.5M labevents is reduced to 36.9M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5f58d626-f7a3-4735-8f8a-38bfc9414a44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tbl_name\n",
      "labevents    36922975\n",
      "pharmacy     10862892\n",
      "dtype: int64\n",
      "tbl_name\n",
      "labevents    350904\n",
      "pharmacy     365269\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.groupby(\"tbl_name\").size())\n",
    "print(df[['subject_id', 'tbl_name']].drop_duplicates().groupby(\"tbl_name\").size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "43231f2f-1caf-4eb9-b0cd-f76dfae72f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv(\"./full_db_basic_preprocessed.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e92138-24ba-48c5-bc20-b2756e2a0af6",
   "metadata": {},
   "source": [
    "#### 2.3 Group loinc codes to panels \n",
    "[Loinc Panels](https://loinc.org/51992-6/panel) are groups of loinc codes (identified by parent id) of related laborotary items. Since a lot lab items are ordered concurrently, it is meaningul to group them to reduce both computaitonal complexity and intepretability of results. For example, loinc parent id *51992-6* refers to heavy meatals panel contains items such as Copper or Zinc test ([Mass/volume] in Serum or Plasma). We implement an algorithm for mapping Loinc codes to parents based on the method introduced by Jianqiang Li et al. ([link](https://pubmed.ncbi.nlm.nih.gov/30346297/)), known as Breaking Down Same Time Concurrent Events (STCE). The concept involves identifying the largest subset in the sequence of ordered lab tests that corresponds to a panel. For instance, if a patient orders lab items \"ABCDE,\" and \"ABC\" belong to a panel, they are assigned the panel code, and the algorithm iterates on the remaining \"DE\". Any items that aren't mapped to a panel code remain unchanged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "57910aa2-7532-41d5-8b6e-b0935b5b62b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./full_db_basic_preprocessed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c28c9aa9-34a5-44a0-a849-912689b7ee54",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = convert_loinc_to_panel(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eead71fe-2ed4-4a86-bf4c-71039a1974d1",
   "metadata": {},
   "source": [
    "##### After groupping to panels 36.9M is reduced to 28.1M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0b65fb93-34e4-4c9f-83c6-e9d1352e621d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tbl_name\n",
      "labevents    28099290\n",
      "pharmacy     10862892\n",
      "dtype: int64\n",
      "tbl_name\n",
      "labevents    350904\n",
      "pharmacy     365269\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.groupby(\"tbl_name\").size())\n",
    "print(df[['subject_id', 'tbl_name']].drop_duplicates().groupby(\"tbl_name\").size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cecbff9-306b-4cd9-b4f6-73b93ce4d305",
   "metadata": {},
   "source": [
    "#### 2.4 Map 5-digit codes to pharmacy\n",
    "Since medications in MIMIC lack associated IDs, we assign them unique 5-digit codes for enumeration. To indicate the origin of each item ID, we prepend the first three letters of each table as prefixes to the codes ('lab' for labevents, 'pha' for pharmacy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f0862bf4-0fdd-4c4f-84ba-2a480d844cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "pharm_mapping = generate_string_pharm(df)\n",
    "df = map_pharmacy_codes(df, pharm_mapping)\n",
    "df = add_prefix(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "950b3883-a652-453c-87b5-5da86551134f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pharm_mapping.to_csv(\"./pharm_mapping.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0886c52-6d3e-4d88-917c-a7c74de5171d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>charttime</th>\n",
       "      <th>col_id</th>\n",
       "      <th>tbl_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16552715_25857688</td>\n",
       "      <td>2142-06-15 10:00:57</td>\n",
       "      <td>pha_00000</td>\n",
       "      <td>pharmacy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16552715_25857688</td>\n",
       "      <td>2142-06-14 16:39:12</td>\n",
       "      <td>pha_00001</td>\n",
       "      <td>pharmacy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16552715_25857688</td>\n",
       "      <td>2142-06-15 09:36:45</td>\n",
       "      <td>pha_00002</td>\n",
       "      <td>pharmacy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          subject_id            charttime     col_id  tbl_name\n",
       "0  16552715_25857688  2142-06-15 10:00:57  pha_00000  pharmacy\n",
       "1  16552715_25857688  2142-06-14 16:39:12  pha_00001  pharmacy\n",
       "2  16552715_25857688  2142-06-15 09:36:45  pha_00002  pharmacy"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2c3e4f-d730-4e6a-b6c4-7d4e4ba0f11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv(\"./full_db_basic_preprocessed_after_prefix.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f2a634ae-00f4-480c-b114-e2199998edd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./full_db_basic_preprocessed_after_prefix.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b64bdd3-fc22-44a2-99b2-6e5ff96408f4",
   "metadata": {},
   "source": [
    "#### 2.5 Filter out subjects who had presriptions only and no labevents\n",
    "We only care about those subjects who had both labevents and prescriptions, those who only had prescriptions are filtered out\n",
    "\n",
    "##### Pharmacy transactions are reduced from 10.9M to 105.6M. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e4967855-9d5d-42b8-a47f-7c28dc0f4e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df, df.query(\"tbl_name=='labevents'\")[['subject_id']].drop_duplicates(), on='subject_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca16a271-960a-4acb-aab7-884cf5de63f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tbl_name\n",
      "labevents    28099290\n",
      "pharmacy     10558571\n",
      "dtype: int64\n",
      "tbl_name\n",
      "labevents    350904\n",
      "pharmacy     340034\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.groupby(\"tbl_name\").size())\n",
    "print(df[['subject_id', 'tbl_name']].drop_duplicates().groupby(\"tbl_name\").size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3a4964-80eb-468e-8e70-c4a838440d52",
   "metadata": {},
   "source": [
    "#### 2.6 For each subject create an ordered list of item orders to prepare for itemset mining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "154d3f48-ca89-4be8-bb30-e50c62ccc9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = group_into_list(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "66c10f01-5616-4790-b1da-639b266c4586",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>charttime</th>\n",
       "      <th>col_id_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000032_22595853</td>\n",
       "      <td>2180-05-07 00:10:00</td>\n",
       "      <td>[lab_5792-7, lab_3397-7, lab_5802-4, lab_5811-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000032_22595853</td>\n",
       "      <td>2180-05-07 05:05:00</td>\n",
       "      <td>[lab_6768-6, lab_50676-6, lab_CBC, lab_1742-6,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000032_22595853</td>\n",
       "      <td>2180-05-07 10:11:00</td>\n",
       "      <td>[lab_2531-2, lab_30380-0, lab_26488-7, lab_519...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000032_22841357</td>\n",
       "      <td>2180-06-26 22:45:00</td>\n",
       "      <td>[lab_5792-7, lab_5822-2, lab_5804-0, lab_8247-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000032_22841357</td>\n",
       "      <td>2180-06-27 05:10:00</td>\n",
       "      <td>[lab_6768-6, lab_1742-6, lab_CBC, lab_1975-2, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          subject_id            charttime  \\\n",
       "0  10000032_22595853  2180-05-07 00:10:00   \n",
       "1  10000032_22595853  2180-05-07 05:05:00   \n",
       "2  10000032_22595853  2180-05-07 10:11:00   \n",
       "3  10000032_22841357  2180-06-26 22:45:00   \n",
       "4  10000032_22841357  2180-06-27 05:10:00   \n",
       "\n",
       "                                         col_id_list  \n",
       "0  [lab_5792-7, lab_3397-7, lab_5802-4, lab_5811-...  \n",
       "1  [lab_6768-6, lab_50676-6, lab_CBC, lab_1742-6,...  \n",
       "2  [lab_2531-2, lab_30380-0, lab_26488-7, lab_519...  \n",
       "3  [lab_5792-7, lab_5822-2, lab_5804-0, lab_8247-...  \n",
       "4  [lab_6768-6, lab_1742-6, lab_CBC, lab_1975-2, ...  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "1926dfe8-d4b5-4ba8-91fe-a2f15e422bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"./ready_for_breakdown.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953e0c9a-4c06-4bf2-b489-f5837d8ce0c9",
   "metadata": {},
   "source": [
    "#### 2.7 STCE breakdown with frequent baskets (a.k.a itemsets):\n",
    "In this phase, our goal is to further combine lab events that frequently occur together. While we've already grouped some items by panels, leveraging hospital data allows us to identify commonly co-occurring items. Initially, we generate Frequent Item Baskets using the FPmax ([link](https://www.philippe-fournier-viger.com/spmf/fpmax.pdf)) algorithm, with user-defined minimum support criteria. For instance, if (lab_2075-0, lab_CBC) has a support of 45%, it indicates that 45% of all lab orders included both items, regardless of order. Additionally, we post-process frequent baskets, ensuring that only closed frequent baskets remain, meaning that no superset of the basket can be frequent.\n",
    "\n",
    "Subsequently, each basket is assigned a unique ID. Baskets are then grouped into \"buckets\" by length descending, and within each bucket, items are sorted based on their support (highest first). Finally, we reapply the STCE breakdown algorithm, but instead of using parent LOINCs, we utilize the frequent baskets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ecb887f-b070-4985-a0f6-30ca145ace0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./ready_for_breakdown.csv\", converters={'col_id_list': ast.literal_eval})\n",
    "filtered_df = df[df['col_id_list'].apply(lambda x: len(x) > 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d97f89e-8ced-4cc9-b61b-f7d89b0be753",
   "metadata": {},
   "source": [
    "##### Number of max frequent baskets with differnet support levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eeadf879-9fb0-4a51-b783-b5af506480fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MinSup:0.5 Number of patterns:0\n",
      "MinSup:0.4 Number of patterns:2\n",
      "MinSup:0.3 Number of patterns:3\n",
      "MinSup:0.2 Number of patterns:1\n",
      "MinSup:0.1 Number of patterns:18\n",
      "MinSup:0.05 Number of patterns:20\n"
     ]
    }
   ],
   "source": [
    "supports = [0.5, 0.4, 0.3, 0.2, 0.1, 0.05]\n",
    "for min_sup in supports:\n",
    "    patterns = generate_frequent_itemsets(filtered_df, min_sup)\n",
    "    print(\"MinSup:{s}\".format(s=min_sup), \"Number of patterns:{n}\".format(n=patterns.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65d49f00-b16a-4f97-89a3-0f39ceddc3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# It seems? aorund 10% is optimal because lower supports yields similar number of patterns\n",
    "patterns = generate_frequent_itemsets(filtered_df, 0.10)\n",
    "# Add lenth of each basket (a.k.a. itemset)\n",
    "patterns['length'] = patterns['itemsets'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56d71557-db15-47c4-a817-c9361d5897ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>support</th>\n",
       "      <th>itemsets</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.100637</td>\n",
       "      <td>(lab_2075-0, lab_34548-8, lab_1963-8, lab_1975-2, lab_CBC)</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.100018</td>\n",
       "      <td>(lab_34548-8, lab_1963-8, lab_1975-2, lab_1920-8, lab_6768-6)</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.100043</td>\n",
       "      <td>(lab_2075-0, lab_1963-8, lab_1975-2, lab_1920-8, lab_6768-6)</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.100005</td>\n",
       "      <td>(lab_2075-0, lab_34548-8, lab_1963-8, lab_6768-6, lab_1975-2, lab_1742-6)</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.101068</td>\n",
       "      <td>(lab_2075-0, lab_34548-8, lab_1963-8, lab_1975-2, lab_1920-8, lab_1742-6)</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.100140</td>\n",
       "      <td>(lab_2075-0, lab_34548-8, lab_6768-6, lab_1975-2, lab_1920-8, lab_1742-6)</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.101232</td>\n",
       "      <td>(lab_2075-0, lab_34548-8, lab_1963-8, lab_6768-6, lab_1920-8, lab_CBC, lab_1742-6)</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.100005</td>\n",
       "      <td>(lab_14979-9, lab_2075-0, lab_70219-1, lab_19123-9)</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.101886</td>\n",
       "      <td>(lab_2075-0, lab_34548-8, lab_1963-8, lab_5902-2, lab_14979-9, lab_70219-1, lab_6301-6, lab_CBC)</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.124893</td>\n",
       "      <td>(lab_2075-0, lab_19123-9, lab_34548-8, lab_1963-8, lab_5902-2, lab_14979-9, lab_6301-6, lab_CBC)</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.100012</td>\n",
       "      <td>(lab_19123-9, lab_1963-8, lab_5902-2, lab_50676-6, lab_6301-6, lab_CBC)</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.100013</td>\n",
       "      <td>(lab_19123-9, lab_34548-8, lab_5902-2, lab_50676-6, lab_6301-6, lab_CBC)</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.100071</td>\n",
       "      <td>(lab_2075-0, lab_19123-9, lab_5902-2, lab_50676-6, lab_6301-6, lab_CBC)</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.100233</td>\n",
       "      <td>(lab_2075-0, lab_34548-8, lab_1963-8, lab_5902-2, lab_50676-6, lab_6301-6, lab_CBC)</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.101883</td>\n",
       "      <td>(lab_2075-0, lab_19123-9, lab_34548-8, lab_1963-8, lab_50676-6, lab_70219-1, lab_6301-6, lab_5902-2)</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.103686</td>\n",
       "      <td>(lab_2075-0, lab_19123-9, lab_34548-8, lab_1963-8, lab_5902-2, lab_70219-1, lab_6301-6, lab_CBC)</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.217325</td>\n",
       "      <td>(lab_2075-0, lab_19123-9, lab_34548-8, lab_1963-8, lab_50676-6, lab_70219-1, lab_CBC)</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     support  \\\n",
       "0   0.100637   \n",
       "1   0.100018   \n",
       "2   0.100043   \n",
       "3   0.100005   \n",
       "4   0.101068   \n",
       "5   0.100140   \n",
       "6   0.101232   \n",
       "8   0.100005   \n",
       "9   0.101886   \n",
       "10  0.124893   \n",
       "11  0.100012   \n",
       "12  0.100013   \n",
       "13  0.100071   \n",
       "14  0.100233   \n",
       "15  0.101883   \n",
       "16  0.103686   \n",
       "17  0.217325   \n",
       "\n",
       "                                                                                                itemsets  \\\n",
       "0                                             (lab_2075-0, lab_34548-8, lab_1963-8, lab_1975-2, lab_CBC)   \n",
       "1                                          (lab_34548-8, lab_1963-8, lab_1975-2, lab_1920-8, lab_6768-6)   \n",
       "2                                           (lab_2075-0, lab_1963-8, lab_1975-2, lab_1920-8, lab_6768-6)   \n",
       "3                              (lab_2075-0, lab_34548-8, lab_1963-8, lab_6768-6, lab_1975-2, lab_1742-6)   \n",
       "4                              (lab_2075-0, lab_34548-8, lab_1963-8, lab_1975-2, lab_1920-8, lab_1742-6)   \n",
       "5                              (lab_2075-0, lab_34548-8, lab_6768-6, lab_1975-2, lab_1920-8, lab_1742-6)   \n",
       "6                     (lab_2075-0, lab_34548-8, lab_1963-8, lab_6768-6, lab_1920-8, lab_CBC, lab_1742-6)   \n",
       "8                                                    (lab_14979-9, lab_2075-0, lab_70219-1, lab_19123-9)   \n",
       "9       (lab_2075-0, lab_34548-8, lab_1963-8, lab_5902-2, lab_14979-9, lab_70219-1, lab_6301-6, lab_CBC)   \n",
       "10      (lab_2075-0, lab_19123-9, lab_34548-8, lab_1963-8, lab_5902-2, lab_14979-9, lab_6301-6, lab_CBC)   \n",
       "11                               (lab_19123-9, lab_1963-8, lab_5902-2, lab_50676-6, lab_6301-6, lab_CBC)   \n",
       "12                              (lab_19123-9, lab_34548-8, lab_5902-2, lab_50676-6, lab_6301-6, lab_CBC)   \n",
       "13                               (lab_2075-0, lab_19123-9, lab_5902-2, lab_50676-6, lab_6301-6, lab_CBC)   \n",
       "14                   (lab_2075-0, lab_34548-8, lab_1963-8, lab_5902-2, lab_50676-6, lab_6301-6, lab_CBC)   \n",
       "15  (lab_2075-0, lab_19123-9, lab_34548-8, lab_1963-8, lab_50676-6, lab_70219-1, lab_6301-6, lab_5902-2)   \n",
       "16      (lab_2075-0, lab_19123-9, lab_34548-8, lab_1963-8, lab_5902-2, lab_70219-1, lab_6301-6, lab_CBC)   \n",
       "17                 (lab_2075-0, lab_19123-9, lab_34548-8, lab_1963-8, lab_50676-6, lab_70219-1, lab_CBC)   \n",
       "\n",
       "    length  \n",
       "0        5  \n",
       "1        5  \n",
       "2        5  \n",
       "3        6  \n",
       "4        6  \n",
       "5        6  \n",
       "6        7  \n",
       "8        4  \n",
       "9        8  \n",
       "10       8  \n",
       "11       6  \n",
       "12       6  \n",
       "13       6  \n",
       "14       7  \n",
       "15       8  \n",
       "16       8  \n",
       "17       7  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "patterns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297f0dd2-f8de-4d76-9d2e-9577c39502b9",
   "metadata": {},
   "source": [
    "##### Apply the STCE algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ca3e0f97-a089-45e6-aaff-3fe85a4b2083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain unique ids for each basket\n",
    "id_mapping_basket, mapping_basket_df = basket_mappings(patterns)\n",
    "buckets = get_buckets(patterns)\n",
    "# Perform the STCE breakdown algorithm\n",
    "df['col_id_list'] = df[\"col_id_list\"].apply(lambda x: break_down(frozenset(x), buckets, id_mapping_basket))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0438d924-e6f9-4d3b-b21d-9ca795506f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_basket_df.to_csv(\"./mapping_basket_df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6fba4c-14e0-4fd2-8daa-b1d98276d554",
   "metadata": {},
   "source": [
    "##### After STCE breakdown (with 10% min sup), labevents are reduced to 20.5M from 28.1M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "775cfcd8-b01b-46f5-b76c-72acf5fff61c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows with 'pha': 10558571\n",
      "Number of rows with 'lab': 20487101\n"
     ]
    }
   ],
   "source": [
    "temp = df.explode('col_id_list')\n",
    "pha_count = temp[temp['col_id_list'].str.startswith('pha')].shape[0]\n",
    "lab_count = temp[temp['col_id_list'].str.startswith('lab')].shape[0]\n",
    "print(\"Number of rows with 'pha':\", pha_count)\n",
    "print(\"Number of rows with 'lab':\", lab_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "82c91a9c-dce3-4f22-9aff-da1caa85520e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(\"./ready_for_seq_mining.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac855ae0-f717-4797-91f1-7a419744ee09",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd05a192-6fbe-4706-9083-6f87b8b4bcca",
   "metadata": {},
   "source": [
    "####  2.8 Combine datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2a4612-3c79-40b5-b8cb-cf03a0b75afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_datasets()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f605edc-5dcc-4502-9aaf-5a19d606d174",
   "metadata": {},
   "source": [
    "##### How many diagnosis events before combining?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cc878f6d-ec7e-4cc6-992c-48803bb648e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4756210"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"diag3.csv\").drop_duplicates(subset=['subject_id', 'seq_num']).shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353a511d-fd95-4deb-84f0-21d7d7af6080",
   "metadata": {},
   "source": [
    "##### Counts after preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2d1f90af-77ae-4fd8-bb38-50be6460cf87",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.read_csv(\"arules_input_final_mimic_raw.txt\", converters={'col_id_list': ast.literal_eval}).explode('col_id_list')\n",
    "pha_count = temp[temp['col_id_list'].str.startswith('pha')].shape[0]\n",
    "lab_count = temp[temp['col_id_list'].str.startswith('lab')].shape[0]\n",
    "diag_count = temp[temp['col_id_list'].str.startswith('diag')].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "97e47614-ce8c-4b95-9ae5-1b57953bfd58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pharmacy: 9613364\n",
      "labevents: 15045636\n",
      "diagnoses: 4313675\n"
     ]
    }
   ],
   "source": [
    "print(\"pharmacy:\", pha_count)\n",
    "print(\"labevents:\", lab_count)\n",
    "print(\"diagnoses:\", diag_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4266774d-3519-4114-b652-3fb25058793f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### aruleSequences input\n",
    "def list_to_str(lst):\n",
    "    return '\\t'.join(map(str, lst)) if isinstance(lst, list) else ''\n",
    "unioned['col_id_list'] = unioned['col_id_list'].apply(list_to_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e93c0a8-c57b-4461-99ef-877630269918",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to txt\n",
    "unioned.to_csv('arules_input_final.txt', \n",
    "                 sep=' ', \n",
    "                 index=False, \n",
    "                 header=False,\n",
    "                 na_rep='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4304f76f-d787-4c15-9426-25afe07e0ca4",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b6a1b7-b5b6-403a-9a30-73acd783832b",
   "metadata": {},
   "source": [
    "## Mappings behind codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff3e2143-41e2-4cce-b376-28961d49afab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loinc_panels = pd.read_csv(\"./mimic_loinc_panels.csv\")\n",
    "lonic = pd.read_csv(\"./mimic_to_loinc.csv\") \n",
    "pharm_mapping = pd.read_csv(\"./pharm_mapping.csv\", dtype={'new_col_id': str})\n",
    "mapping_basket_df = pd.read_csv(\"./mappings/mapping_basket_df.csv\", converters={'basket': eval,'basket_id': eval})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
